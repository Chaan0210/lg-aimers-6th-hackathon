{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from scipy.stats import rankdata\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import miceforest as mf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SEED = 42\n",
    "    N_SPLITS = 10\n",
    "    N_TOP_FOLDS = 5\n",
    "\n",
    "    TRAIN_PATH = './data/train.csv'\n",
    "    TEST_PATH = './data/test.csv'\n",
    "    SUBMISSION_PATH = './data/sample_submission.csv'\n",
    "    MICE_MODEL_PATH = './kds_model.pkl'\n",
    "    OUTPUT_FILENAME = 'final_ensemble_submission.csv'\n",
    "\n",
    "    LGB_PARAMS = {\n",
    "        'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt',\n",
    "        'n_estimators': 2000, 'learning_rate': 0.01, 'num_leaves': 20,\n",
    "        'max_depth': 5, 'seed': SEED, 'n_jobs': -1, 'verbose': -1,\n",
    "        'colsample_bytree': 0.7, 'subsample': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1\n",
    "    }\n",
    "    XGB_PARAMS = {\n",
    "        'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "        'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 5,\n",
    "        'seed': SEED, 'n_jobs': -1, 'colsample_bytree': 0.8, 'subsample': 0.8, 'early_stopping_rounds': 200\n",
    "    }\n",
    "    CAT_PARAMS = {\n",
    "        'loss_function': 'Logloss', 'eval_metric': 'AUC', 'iterations': 3000,\n",
    "        'learning_rate': 0.05, 'depth': 7, 'random_seed': SEED,\n",
    "        'verbose': 0, 'task_type': 'CPU',\n",
    "        'bagging_temperature': 0.01, 'l2_leaf_reg': 5, 'random_strength': 0.9,\n",
    "        'auto_class_weights': 'Balanced', 'early_stopping_rounds': 200\n",
    "    }\n",
    "    ENSEMBLE_WEIGHTS = {'lgbm': 1.0, 'xgb': 1.2, 'cat': 1.2}\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    @staticmethod\n",
    "    def load_data():\n",
    "        train_df = pd.read_csv(Config.TRAIN_PATH)\n",
    "        test_df = pd.read_csv(Config.TEST_PATH)\n",
    "        test_ids = test_df['ID']\n",
    "        train_df.drop(columns=['ID'], inplace=True)\n",
    "        test_df.drop(columns=['ID'], inplace=True)\n",
    "        return train_df, test_df, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "    def _number_mapping(self, df):\n",
    "        ivf_cols = ['IVF 임신 횟수', 'IVF 출산 횟수', 'DI 임신 횟수', 'DI 출산 횟수', 'IVF 시술 횟수', '총 임신 횟수', 'DI 시술 횟수', '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 출산 횟수']\n",
    "        mapping = {'0회': 0, '1회': 1, '2회': 2, '3회': 3, '4회': 4, '5회': 5, '6회 이상': 6}\n",
    "        for col in ivf_cols:\n",
    "            if col in df.columns: df[col] = pd.to_numeric(df[col].replace(mapping), errors='coerce')\n",
    "        return df\n",
    "\n",
    "    def _handle_di_missing(self, df):\n",
    "        di_nan_col = ['미세주입된 난자 수', '미세주입에서 생성된 배아 수', '총 생성 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 채취 경과일', '난자 해동 경과일', '배아 이식 경과일', '배아 해동 경과일', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '단일 배아 이식 여부', '난자 혼합 경과일', '임신 시도 또는 마지막 임신 경과 연수']\n",
    "        row = df['시술 유형'] == \"DI\"\n",
    "        df.loc[row, di_nan_col] = df.loc[row, di_nan_col].fillna(0)\n",
    "        return df\n",
    "\n",
    "    def _get_or_train_mice_model(self, df, target_columns, model_path):\n",
    "        try:\n",
    "            mice_mdl = joblib.load(model_path)\n",
    "            print(\"Pre-trained MICE model loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"MICE model not found. Training a new MICE model...\")\n",
    "            df_subset = df[target_columns].copy()\n",
    "            mice_mdl = mf.ImputationKernel(df_subset, random_state=self.seed)\n",
    "            mice_mdl.mice(iterations=5, n_estimators=50, n_jobs=-1)\n",
    "            joblib.dump(mice_mdl, model_path)\n",
    "            print(f\"New MICE model trained and saved to {model_path}\")\n",
    "        return mice_mdl\n",
    "\n",
    "    def _impute_with_mice(self, train_df, test_df, model_path):\n",
    "        target_cols = ['미세주입된 난자 수', '미세주입에서 생성된 배아 수', '총 생성 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 채취 경과일', '난자 해동 경과일', '배아 이식 경과일', '배아 해동 경과일', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '단일 배아 이식 여부', '난자 혼합 경과일', '임신 시도 또는 마지막 임신 경과 연수']\n",
    "        mice_mdl = self._get_or_train_mice_model(train_df, target_cols, model_path)\n",
    "        \n",
    "        train_imputed = train_df.copy()\n",
    "        train_imputed[target_cols] = mice_mdl.complete_data()\n",
    "        print('MICE: Training data imputed.')\n",
    "\n",
    "        test_imputed = test_df.copy()\n",
    "        test_kernel = mice_mdl.impute_new_data(test_df[target_cols])\n",
    "        test_imputed[target_cols] = test_kernel.complete_data()\n",
    "        print('MICE: Test data imputed.')\n",
    "        return train_imputed, test_imputed\n",
    "\n",
    "    def _create_features(self, df):\n",
    "        df['난자 성공률'] = np.where(df['수집된 신선 난자 수'] == 0, -1, df['미세주입된 난자 수'] / df['수집된 신선 난자 수'])\n",
    "        df['저장된 배아 사용률'] = np.where(df['총 생성 배아 수'] + df['해동된 배아 수'] == 0, -1, df['저장된 배아 수'] / (df['총 생성 배아 수'] + df['해동된 배아 수']))\n",
    "        df['IVF 임신률'] = np.where(df['IVF 시술 횟수'] == 0, -1, df['IVF 임신 횟수'] / df['IVF 시술 횟수'])\n",
    "        df['총 출산률'] = np.where(df['총 임신 횟수'] == 0, -1, df['총 출산 횟수'] / df['총 임신 횟수'])\n",
    "        df['미세주입 배아 생성률'] = np.where(df['미세주입된 난자 수'] == 0, -1, df['미세주입에서 생성된 배아 수'] / df['미세주입된 난자 수'])\n",
    "        df['총 사용 배아'] = df['해동된 배아 수'] + df['총 생성 배아 수']\n",
    "        df['대리모 여부'] = df['대리모 여부'].fillna(-1)\n",
    "        df['시술 당시 나이'] = df['시술 당시 나이'].replace('알 수 없음', '만45-50세')\n",
    "        df[\"난자 기증자 나이\"] = df[\"난자 기증자 나이\"].replace({'알 수 없음': '만 21-25세'})\n",
    "        pg_cols = [\"착상 전 유전 검사 사용 여부\", \"착상 전 유전 진단 사용 여부\", \"PGD 시술 여부\", \"PGS 시술 여부\"]\n",
    "        for col in pg_cols: df[col] = df[col].fillna(0)\n",
    "        df[\"과거 유전자 검사 사용 여부\"] = df[\"착상 전 유전 검사 사용 여부\"] + df[\"착상 전 유전 진단 사용 여부\"]\n",
    "        df[\"현재 검사 사용 여부\"] = df[\"PGD 시술 여부\"] + df[\"PGS 시술 여부\"]\n",
    "        df[\"나이\"] = df[\"시술 당시 나이\"]\n",
    "        mask_donor = (df[\"난자 출처\"] == \"기증 제공\") & (df[\"난자 기증자 나이\"] != \"알 수 없음\")\n",
    "        df.loc[mask_donor, \"나이\"] = df.loc[mask_donor, \"난자 기증자 나이\"]\n",
    "        male_fail = [\"불임 원인 - 남성 요인\", \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\", \"불임 원인 - 정자 형태\"]\n",
    "        female_fail = [\"불임 원인 - 난관 질환\", \"불임 원인 - 배란 장애\", \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\"]\n",
    "        df[\"남성 불임 심각도\"] = df[male_fail].sum(axis=1)\n",
    "        df[\"여성 불임 심각도\"] = df[female_fail].sum(axis=1)\n",
    "        df['난임 여부'] = df['총 시술 횟수'] - df['총 임신 횟수']\n",
    "        df['유산 여부'] = (df['총 임신 횟수'] - df['총 출산 횟수']).apply(lambda x: 1 if x > 0 else 0)\n",
    "        return df\n",
    "\n",
    "    def transform(self, train_df, test_df):\n",
    "        train_df = self._handle_di_missing(train_df)\n",
    "        test_df = self._handle_di_missing(test_df)\n",
    "        train_df, test_df = self._impute_with_mice(train_df, test_df, Config.MICE_MODEL_PATH)\n",
    "        train_df = self._number_mapping(train_df)\n",
    "        test_df = self._number_mapping(test_df)\n",
    "        train_df = self._create_features(train_df)\n",
    "        test_df = self._create_features(test_df)\n",
    "        y_train = train_df['임신 성공 여부']\n",
    "        drop_cols = ['임신 성공 여부', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인']\n",
    "        train_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "        test_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "        categorical_features = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        for col in categorical_features:\n",
    "            train_df[col] = train_df[col].astype(str).astype('category')\n",
    "            test_df[col] = test_df[col].astype(str).astype('category')\n",
    "\n",
    "        return train_df, test_df, y_train, categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleTrainer:\n",
    "    def __init__(self, lgb_params, xgb_params, cat_params, n_splits, seed):\n",
    "        self.lgb_params = lgb_params\n",
    "        self.xgb_params = xgb_params\n",
    "        self.cat_params = cat_params\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def train(self, X, y, categorical_features):\n",
    "        auc_scores = {'lgbm': [], 'xgb': [], 'cat': []}\n",
    "        test_preds = {'lgbm': [], 'xgb': [], 'cat': []}\n",
    "\n",
    "        scale_pos_weight = y.value_counts()[0] / y.value_counts()[1]\n",
    "        self.lgb_params['scale_pos_weight'] = scale_pos_weight\n",
    "        self.xgb_params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(self.skf.split(X, y)):\n",
    "            print(f'===== Fold {fold+1}/{self.skf.get_n_splits()} =====')\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "            self._train_lgbm(X_tr, y_tr, X_val, y_val, auc_scores, test_preds, X, fold)\n",
    "            self._train_xgb(X_tr, y_tr, X_val, y_val, auc_scores, test_preds, X, categorical_features, fold)\n",
    "            self._train_cat(X_tr, y_tr, X_val, y_val, auc_scores, test_preds, X, categorical_features, fold)\n",
    "\n",
    "        print(\"All models training complete.\")\n",
    "        return auc_scores, test_preds\n",
    "\n",
    "    def _train_lgbm(self, X_tr, y_tr, X_val, y_val, scores, preds, X_test, fold):\n",
    "        print(\"Training LightGBM...\")\n",
    "        model = lgb.LGBMClassifier(**self.lgb_params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric='auc', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "        pred = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, pred)\n",
    "        scores['lgbm'].append((auc, fold))\n",
    "        preds['lgbm'].append(model.predict_proba(X_test)[:, 1])\n",
    "        print(f\"LGBM AUC: {auc:.5f}\")\n",
    "\n",
    "    def _train_xgb(self, X_tr, y_tr, X_val, y_val, scores, preds, X_test, cat_feats, fold):\n",
    "        print(\"Training XGBoost...\")\n",
    "        X_tr_xgb, X_val_xgb, X_test_xgb = X_tr.copy(), X_val.copy(), X_test.copy()\n",
    "        for col in cat_feats:\n",
    "            X_tr_xgb[col] = X_tr_xgb[col].cat.codes\n",
    "            X_val_xgb[col] = X_val_xgb[col].cat.codes\n",
    "            X_test_xgb[col] = X_test_xgb[col].cat.codes\n",
    "        model = xgb.XGBClassifier(**self.xgb_params)\n",
    "        model.fit(X_tr_xgb, y_tr, eval_set=[(X_val_xgb, y_val)], verbose=False)\n",
    "        pred = model.predict_proba(X_val_xgb)[:, 1]\n",
    "        auc = roc_auc_score(y_val, pred)\n",
    "        scores['xgb'].append((auc, fold))\n",
    "        preds['xgb'].append(model.predict_proba(X_test_xgb)[:, 1])\n",
    "        print(f\"XGBoost AUC: {auc:.5f}\")\n",
    "\n",
    "    def _train_cat(self, X_tr, y_tr, X_val, y_val, scores, preds, X_test, cat_feats, fold):\n",
    "        print(\"Training CatBoost...\")\n",
    "        model = CatBoostClassifier(**self.cat_params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], cat_features=cat_feats, verbose=0)\n",
    "        pred = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, pred)\n",
    "        scores['cat'].append((auc, fold))\n",
    "        preds['cat'].append(model.predict_proba(X_test)[:, 1])\n",
    "        print(f\"CatBoost AUC: {auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(test_preds, auc_scores, weights, top_n, test_ids, filename):\n",
    "    def weighted_rank_ensemble(predictions, weights):\n",
    "        ranked_preds = np.array([rankdata(pred) for pred in predictions])\n",
    "        weighted_avg_rank = np.average(ranked_preds, axis=0, weights=weights)\n",
    "        return weighted_avg_rank / np.max(weighted_avg_rank)\n",
    "\n",
    "    selected_preds = []\n",
    "    selected_weights = []\n",
    "\n",
    "    print(f\"Ensembling top {top_n} folds from each model...\")\n",
    "    for model_type in ['lgbm', 'xgb', 'cat']:\n",
    "        top_folds = sorted(auc_scores[model_type], reverse=True, key=lambda x: x[0])[:top_n]\n",
    "        fold_indices = [fold_idx for _, fold_idx in top_folds]\n",
    "        print(f\"{model_type.upper()} selected folds (AUC): {[(f'{auc:.5f}', idx) for auc, idx in top_folds]}\")\n",
    "        selected_preds += [test_preds[model_type][idx] for idx in fold_indices]\n",
    "        selected_weights += [weights[model_type]] * len(fold_indices)\n",
    "\n",
    "    final_predictions = weighted_rank_ensemble(selected_preds, selected_weights)\n",
    "    submission_df = pd.DataFrame({'ID': test_ids, 'probability': final_predictions})\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"Submission file '{filename}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load Data\n",
    "    train_raw, test_raw, test_ids = DataManager.load_data()\n",
    "\n",
    "    # Feature Engineering\n",
    "    feature_engineer = FeatureEngineer(seed=Config.SEED)\n",
    "    X_train, X_test, y_train, cat_features = feature_engineer.transform(train_raw, test_raw)\n",
    "\n",
    "    # Train Ensemble Models\n",
    "    trainer = EnsembleTrainer(Config.LGB_PARAMS, Config.XGB_PARAMS, Config.CAT_PARAMS, Config.N_SPLITS, Config.SEED)\n",
    "    auc_scores_dict, test_pred_dict = trainer.train(X_train, y_train, cat_features)\n",
    "\n",
    "    # Generate Submission File\n",
    "    generate_submission(test_pred_dict, auc_scores_dict, Config.ENSEMBLE_WEIGHTS, Config.N_TOP_FOLDS, test_ids, Config.OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
