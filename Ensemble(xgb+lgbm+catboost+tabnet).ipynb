{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740491034081,
     "user": {
      "displayName": "박동찬",
      "userId": "07837218056687676077"
     },
     "user_tz": -540
    },
    "id": "YVyobm1cznbF",
    "outputId": "5d804ace-88b5-4cb0-df19-fb5d0efb3ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 41255,
     "status": "error",
     "timestamp": 1740491915479,
     "user": {
      "displayName": "박동찬",
      "userId": "07837218056687676077"
     },
     "user_tz": -540
    },
    "id": "L2x295nDzObg",
    "outputId": "00b1f0d2-a11d-4666-be14-d9f0c5138b60"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet\n",
    "!pip install catboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# ---------------------------\n",
    "# Data Loader Function\n",
    "# ---------------------------\n",
    "def load_data(train_file, test_file, submission_file):\n",
    "    train = pd.read_csv(train_file).drop(columns=['ID'])\n",
    "    test = pd.read_csv(test_file).drop(columns=['ID'])\n",
    "    X = train.drop('임신 성공 여부', axis=1)\n",
    "    y = train['임신 성공 여부']\n",
    "    print(\"✅ 데이터 로드 완료!\")\n",
    "    print(\"train.csv의 X shape:\", X.shape)\n",
    "    print(\"train.csv의 y shape:\", y.shape)\n",
    "    return X, y, test, submission_file\n",
    "\n",
    "# ---------------------------\n",
    "# Preprocessing Class\n",
    "# ---------------------------\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        # 나이 매핑 정보\n",
    "        self.age_mapping = {\n",
    "            \"만18-34세\": 1,\n",
    "            \"만35-37세\": 2,\n",
    "            \"만38-39세\": 3,\n",
    "            \"만40-42세\": 4,\n",
    "            \"만43-44세\": 5,\n",
    "            \"만45-50세\": 6,\n",
    "            \"알 수 없음\": 3.5  # 중립값\n",
    "        }\n",
    "        # 삭제할 컬럼들\n",
    "        self.drop_columns_cat = [\"배란 유도 유형\", \"불임 원인-여성요인\"]\n",
    "        self.drop_columns_numeric = [\"난자 채취 경과일\", \"난자 해동 경과일\", \"난자 혼합 경과일\", \"임신 시도 또는 마지막 임신 경과 연수\", \"배아 해동 경과일\"]\n",
    "\n",
    "        # 전처리할 카테고리형 컬럼 리스트\n",
    "        self.categorical_columns = [\n",
    "            \"시술 시기 코드\",\n",
    "            \"시술 유형\",\n",
    "            \"특정 시술 유형\",\n",
    "            \"배란 자극 여부\",\n",
    "            \"단일 배아 이식 여부\",\n",
    "            \"착상 전 유전 진단 사용 여부\",\n",
    "            \"남성 주 불임 원인\",\n",
    "            \"남성 부 불임 원인\",\n",
    "            \"여성 주 불임 원인\",\n",
    "            \"여성 부 불임 원인\",\n",
    "            \"부부 주 불임 원인\",\n",
    "            \"부부 부 불임 원인\",\n",
    "            \"불명확 불임 원인\",\n",
    "            \"불임 원인 - 난관 질환\",\n",
    "            \"불임 원인 - 남성 요인\",\n",
    "            \"불임 원인 - 배란 장애\",\n",
    "            \"불임 원인 - 자궁경부 문제\",\n",
    "            \"불임 원인 - 자궁내막증\",\n",
    "            \"불임 원인 - 정자 농도\",\n",
    "            \"불임 원인 - 정자 운동성\",\n",
    "            \"불임 원인 - 정자 형태\",\n",
    "            \"배아 생성 주요 이유\",\n",
    "            \"총 시술 횟수\",\n",
    "            \"클리닉 내 총 시술 횟수\",\n",
    "            \"IVF 시술 횟수\",\n",
    "            \"DI 시술 횟수\",\n",
    "            \"총 임신 횟수\",\n",
    "            \"IVF 임신 횟수\",\n",
    "            \"DI 임신 횟수\",\n",
    "            \"총 출산 횟수\",\n",
    "            \"IVF 출산 횟수\",\n",
    "            \"DI 출산 횟수\",\n",
    "            \"난자 출처\",\n",
    "            \"정자 출처\",\n",
    "            \"난자 기증자 나이\",\n",
    "            \"정자 기증자 나이\",\n",
    "            \"동결 배아 사용 여부\",\n",
    "            \"신선 배아 사용 여부\",\n",
    "            \"기증 배아 사용 여부\",\n",
    "            \"대리모 여부\"\n",
    "        ]\n",
    "        # 수치형 컬럼 리스트\n",
    "        self.numeric_columns = [\n",
    "            \"총 생성 배아 수\",\n",
    "            \"미세주입된 난자 수\",\n",
    "            \"미세주입에서 생성된 배아 수\",\n",
    "            \"이식된 배아 수\",\n",
    "            \"미세주입 배아 이식 수\",\n",
    "            \"저장된 배아 수\",\n",
    "            \"미세주입 후 저장된 배아 수\",\n",
    "            \"해동된 배아 수\",\n",
    "            \"해동 난자 수\",\n",
    "            \"수집된 신선 난자 수\",\n",
    "            \"저장된 신선 난자 수\",\n",
    "            \"혼합된 난자 수\",\n",
    "            \"파트너 정자와 혼합된 난자 수\",\n",
    "            \"기증자 정자와 혼합된 난자 수\",\n",
    "        ]\n",
    "\n",
    "    def process_age_feature(self, df):\n",
    "        df[\"시술 당시 나이_ordinal\"] = df[\"시술 당시 나이\"].astype(str).map(self.age_mapping)\n",
    "        df[\"시술 당시 나이_ordinal\"] = df[\"시술 당시 나이_ordinal\"].astype(float)\n",
    "        poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "        poly_features = poly.fit_transform(df[[\"시술 당시 나이_ordinal\"]])\n",
    "        df[\"시술 당시 나이^2\"] = poly_features[:, 1]\n",
    "        df[\"시술 당시 나이^3\"] = poly_features[:, 2]\n",
    "        df[\"나이 페널티\"] = df[\"시술 당시 나이_ordinal\"] * (-0.1)\n",
    "        df[\"나이 페널티_2\"] = df[\"시술 당시 나이_ordinal\"] * (-0.2)\n",
    "        df.drop(columns=[\"시술 당시 나이\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def process_categorical_features(self, df):\n",
    "        df[\"착상 전 유전 검사 사용 여부\"] = df[\"착상 전 유전 검사 사용 여부\"].fillna(0)\n",
    "        df[\"PGD 시술 여부\"] = df[\"PGD 시술 여부\"].fillna(0)\n",
    "        df[\"PGS 시술 여부\"] = df[\"PGS 시술 여부\"].fillna(0)\n",
    "        df = df.drop(columns=self.drop_columns_cat, errors=\"ignore\")\n",
    "        for col in self.categorical_columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "        return df\n",
    "\n",
    "    def process_numeric_features(self, df):\n",
    "        df[\"배아 이식 경과일\"] = df[\"배아 이식 경과일\"].fillna(3)\n",
    "        df = df.drop(columns=self.drop_columns_numeric, errors=\"ignore\")\n",
    "        return df\n",
    "\n",
    "    def encode_categorical(self, train_df, test_df):\n",
    "        ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "        train_df[self.categorical_columns] = ordinal_encoder.fit_transform(train_df[self.categorical_columns])\n",
    "        test_df[self.categorical_columns] = ordinal_encoder.transform(test_df[self.categorical_columns])\n",
    "        return train_df, test_df\n",
    "\n",
    "    def scale_numeric(self, train_df, test_df):\n",
    "        scaler = StandardScaler()\n",
    "        train_df[self.numeric_columns] = scaler.fit_transform(train_df[self.numeric_columns])\n",
    "\n",
    "    def preprocess(self, train_df, test_df, y):\n",
    "        train_df = self.process_age_feature(train_df)\n",
    "        test_df = self.process_age_feature(test_df)\n",
    "        train_df = self.process_categorical_features(train_df)\n",
    "        test_df = self.process_categorical_features(test_df)\n",
    "        train_df = self.process_numeric_features(train_df)\n",
    "        test_df = self.process_numeric_features(test_df)\n",
    "        self.scale_numeric(train_df, test_df)\n",
    "        train_df, test_df = self.encode_categorical(train_df, test_df)\n",
    "        # Feature Weighting\n",
    "        train_df[\"시술 당시 나이_weighted\"] = train_df[\"시술 당시 나이_ordinal\"] * 1.5\n",
    "        test_df[\"시술 당시 나이_weighted\"] = test_df[\"시술 당시 나이_ordinal\"] * 1.5\n",
    "        print(\"✅ 데이터 전처리 완료!\")\n",
    "        return train_df, test_df, y\n",
    "\n",
    "# ---------------------------\n",
    "# Resampler Class\n",
    "# ---------------------------\n",
    "class Resampler:\n",
    "    def __init__(self, method='none'):\n",
    "        self.method = method.lower()\n",
    "    def resample(self, X, y):\n",
    "        if self.method == 'undersample':\n",
    "            from imblearn.under_sampling import RandomUnderSampler\n",
    "            sampler = RandomUnderSampler(random_state=42)\n",
    "            X_res, y_res = sampler.fit_resample(X, y)\n",
    "            print(\"✅ Undersampling applied. New shape:\", X_res.shape)\n",
    "        elif self.method == 'oversample':\n",
    "            from imblearn.over_sampling import RandomOverSampler\n",
    "            sampler = RandomOverSampler(random_state=42)\n",
    "            X_res, y_res = sampler.fit_resample(X, y)\n",
    "            print(\"✅ Oversampling applied. New shape:\", X_res.shape)\n",
    "        elif self.method == 'smote':\n",
    "            from imblearn.over_sampling import SMOTE\n",
    "            sampler = SMOTE(random_state=42)\n",
    "            X_res, y_res = sampler.fit_resample(X, y)\n",
    "            print(\"✅ SMOTE applied. New shape:\", X_res.shape)\n",
    "        else:\n",
    "            X_res, y_res = X, y\n",
    "            print(\"✅ No resampling applied.\")\n",
    "        return X_res, y_res\n",
    "\n",
    "# ---------------------------\n",
    "# Model Trainer Class\n",
    "# ---------------------------\n",
    "class ModelTrainer:\n",
    "    def __init__(self, X_train, X_val, y_train, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.base_models = None\n",
    "        self.meta_model = None\n",
    "    def train_xgb(self):\n",
    "        xgb_model = XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            subsample=0.7426464507655118,\n",
    "            n_estimators=461,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.03882069104127232,\n",
    "            colsample_bytree=0.9097334148049476,\n",
    "            tree_method=\"hist\",\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "        xgb_model.fit(self.X_train, self.y_train, eval_set=[(self.X_val, self.y_val)], verbose=True)\n",
    "        auc = roc_auc_score(self.y_val, xgb_model.predict_proba(self.X_val)[:, 1])\n",
    "        print(f\"✅ XGBoost ROC-AUC Score: {auc:.4f}\")\n",
    "        return xgb_model\n",
    "    def train_lgbm(self):\n",
    "        lgbm_model = LGBMClassifier(\n",
    "            n_estimators=527,\n",
    "            learning_rate=0.04148924654004078,\n",
    "            max_depth=5,\n",
    "            num_leaves=85,\n",
    "            subsample=0.8339351226312508,\n",
    "            colsample_bytree=0.6960519772928399,\n",
    "            min_child_samples=46,\n",
    "            random_state=42,\n",
    "        )\n",
    "        lgbm_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            eval_set=[(self.X_val, self.y_val)],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=True)]\n",
    "        )\n",
    "        auc = roc_auc_score(self.y_val, lgbm_model.predict_proba(self.X_val)[:, 1])\n",
    "        print(f\"✅ LGBM ROC-AUC Score: {auc:.4f}\")\n",
    "        return lgbm_model\n",
    "    def train_catboost(self):\n",
    "        catboost_model = CatBoostClassifier(\n",
    "            iterations=607,\n",
    "            learning_rate=0.046970220945236694,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=1.3270415457360085,\n",
    "            border_count=79,\n",
    "            bagging_temperature=1.4405235392731484,\n",
    "            random_strength=0.9001167344802684,\n",
    "            eval_metric=\"AUC\",\n",
    "            random_seed=42,\n",
    "            verbose=100,\n",
    "            task_type=\"GPU\"\n",
    "        )\n",
    "        catboost_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            eval_set=(self.X_val, self.y_val),\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        auc = roc_auc_score(self.y_val, catboost_model.predict_proba(self.X_val)[:, 1])\n",
    "        print(f\"✅ CatBoost ROC-AUC Score: {auc:.4f}\")\n",
    "        return catboost_model\n",
    "    def train_voting_classifier(self, models):\n",
    "        voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "        voting_clf.fit(self.X_train, self.y_train)\n",
    "        auc = roc_auc_score(self.y_val, voting_clf.predict_proba(self.X_val)[:, 1])\n",
    "        print(f\"✅ Voting Classifier ROC-AUC Score: {auc:.4f}\")\n",
    "        return voting_clf\n",
    "\n",
    "# ---------------------------\n",
    "# Main Pipeline\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # 1. Data loading\n",
    "    train_file = \"train.csv\"\n",
    "    test_file = \"test.csv\"\n",
    "    submission_file = \"sample_submission.csv\"\n",
    "    X, y, test_df, submission_file = load_data(train_file, test_file, submission_file)\n",
    "\n",
    "    # 2. Pre-processing\n",
    "    preprocessor = Preprocessor()\n",
    "    X_train_encoded, X_test_encoded, y = preprocessor.preprocess(X.copy(), test_df.copy(), y)\n",
    "\n",
    "    print(\"Pre-processed X shape:\", X_train_encoded.shape)\n",
    "    print(\"Pre-processed y shape:\", y.shape)\n",
    "    print(\"y null 개수:\", y.isnull().sum())\n",
    "\n",
    "    # 2.5. Feature Engineering\n",
    "    X_train_encoded[\"나이_배아이식_상호작용\"] = X_train_encoded[\"시술 당시 나이_ordinal\"] * X_train_encoded[\"배아 이식 경과일\"]\n",
    "    X_test_encoded[\"나이_배아이식_상호작용\"] = X_test_encoded[\"시술 당시 나이_ordinal\"] * X_test_encoded[\"배아 이식 경과일\"]\n",
    "\n",
    "    X_train_encoded[\"나이_총시술횟수_상호작용\"] = X_train_encoded[\"시술 당시 나이_ordinal\"] * X_train_encoded[\"총 시술 횟수\"]\n",
    "    X_test_encoded[\"나이_총시술횟수_상호작용\"] = X_test_encoded[\"시술 당시 나이_ordinal\"] * X_test_encoded[\"총 시술 횟수\"]\n",
    "\n",
    "    X_train_encoded[\"배아생성_이식_상호작용\"] = X_train_encoded[\"총 생성 배아 수\"] * X_train_encoded[\"이식된 배아 수\"]\n",
    "    X_test_encoded[\"배아생성_이식_상호작용\"] = X_test_encoded[\"총 생성 배아 수\"] * X_test_encoded[\"이식된 배아 수\"]\n",
    "\n",
    "    X_train_encoded[\"배아_이식_성공률\"] = X_train_encoded[\"이식된 배아 수\"] / (X_train_encoded[\"총 생성 배아 수\"] + 1)\n",
    "    X_test_encoded[\"배아_이식_성공률\"] = X_test_encoded[\"이식된 배아 수\"] / (X_test_encoded[\"총 생성 배아 수\"] + 1)\n",
    "\n",
    "    # 3. Splitting dataset\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # 4. Resampling\n",
    "    sampling_method = 'none'\n",
    "    resampler = Resampler(method=sampling_method)\n",
    "    X_train_res, y_train_res = resampler.resample(X_train, y_train)\n",
    "    print(\"임신 성공 1 개수:\", (y_train_res == 1).sum())\n",
    "    print(\"임신 실패 0 개수:\", (y_train_res == 0).sum())\n",
    "\n",
    "    # 5. Training\n",
    "    trainer = ModelTrainer(X_train_res, X_val, y_train_res, y_val)\n",
    "    xgb_model = trainer.train_xgb()\n",
    "    lgbm_model = trainer.train_lgbm()\n",
    "    catboost_model = trainer.train_catboost()\n",
    "\n",
    "   # 5.5. Imputation\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    tabnet_model = TabNetClassifier(verbose=1)\n",
    "    # TabNet은 numpy array (float32)와 1차원 target을 받습니다.\n",
    "    X_train_res_np = X_train_res.astype(np.float32).to_numpy()\n",
    "    # 결측치 처리: SimpleImputer로 채워서 TabNet용 데이터를 준비합니다.\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train_res_tabnet = imputer.fit_transform(X_train_res_np)\n",
    "    y_train_res_np = y_train_res.values if isinstance(y_train_res, pd.Series) else y_train_res\n",
    "\n",
    "    tabnet_model.fit(\n",
    "        X_train_res_np, y_train_res_np,\n",
    "        max_epochs=100, patience=10, batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0, drop_last=False\n",
    "    )\n",
    "    print(\"✅ TabNet 모델 학습 완료!\")\n",
    "\n",
    "    # 6. Voting Ensemble\n",
    "    models = [\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('catboost', catboost_model),\n",
    "        ('tabnet', tabnet_model)\n",
    "    ]\n",
    "    voting_clf = trainer.train_voting_classifier(models)\n",
    "\n",
    "    # 7. 테스트 데이터 예측 및 제출 파일 생성\n",
    "    test_proba = voting_clf.predict_proba(X_test_encoded)[:, 1]\n",
    "    age_factor = (3.5 - X_test_encoded[\"시술 당시 나이_ordinal\"]) * 0.001\n",
    "    adjusted_pred_proba = test_proba + age_factor\n",
    "    adjusted_pred_proba = np.clip(adjusted_pred_proba, 0, 1)\n",
    "\n",
    "    submission = pd.read_csv(submission_file)\n",
    "    submission['probability'] = adjusted_pred_proba\n",
    "    output_file = \"tabnet_ensemble_submission.csv\"\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"✅ 최종 제출 파일 저장 완료: {output_file}\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download(output_file)\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
